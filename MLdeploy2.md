# A Set of Practices and Architectures for ML Deployments for Small and Medium Companies (SMBs)
## Disclaimer
This document was generated through a process of researching ML Deployment technologies (API-Server, Docker, Kubernetes, Apache Spark, Seldon Core, Kubeflow, and MLFlow) and experimentation deploying some of the already mentioned solutions. The entire process was designed and performed by one person, and many other technologies were not considered for this experiment because the limited amount of time and knowledge needed to explore more alternative.

## SMBs Specific Challenges - Why this document focus on SMBs?
1. SMBs have limited financial resources.
2. SMBs have difficulties acquiring and retaining digital talent.
3. 3rd Party Proprietary Software/Solutions can generate a Lock-in and, in many cases, the knowledge acquired to use one service is not transferable to other services.

## How this could help
1. Quickly deploy a Machine Learning Model using Open-Source solutions.
2. Manage the model versioning, governance, and traceability of the process.
3. Auto-scalability, to ensure cost and performance efficiency of the system.
4. Be able to deploy models using similar technologies used in the building and training stages.
5. Automate manual processes to leave more time for Data Science, and less for configuration and scalability of the platform.
6. Maintain a cost-efficient platform, which can adapt to the business’s needs.

## Best Practices
1. The system should have a model repository, that allows Accessing and Versioning them. --> This will allow the business to compare models and choose which one to deploy depending on a desired 
   metric(e.g., r2, F1, accuracy, etc.)/performance(e.g., time to process).
2. Have a system with Traceability capabilities, where the company can trace a prediction back to the model and data that generated it. --> To take actions in case of errors or black box 
   problems (Newell and Marabelli, 2015).
3. Monitor Models in Testing and Production environments. --> These could lead your system to not to attend all the requests made to the platform by users or other systems (John, Olsson, and Bosch, 2021).
4. Look for solutions that help teams to deploy faster and perform continuous updates. --> Time passes, data gets outdated. so do our models.

## Recommended Architecture Diagram to Implement
### Description of the system
The system is an implementation of Seldon Core, that uses Kubernetes as the main platform to maintain all the services needed to deploy a (or multiple) machine learning model. Kubernetes hosts and orchestrates Seldon Core, Istio, and the models that Seldon will be in charge of deploying.
This solution will allow Data Scientist to deploy Machine Learning Models without needing to have knowledge about web servers, docker or other deployment framework. The system is designed so Data Scientists can write their models using Python, TensorFlow, Pytorch, SKLearn, MLFlow libraries, and Seldon Core will generate a container wrapping the model in a web server to deploy it to Kubernetes, so Data Scientists do not need to do so. With this approach, businesses can leverage their work leaving Kubernetes the tasks of orchestrating and scaling up/down the services to optimize the use of infrastructure, and be robust against app crashes. Additionally, we suggest implementing mlFlow to keep tracking every model generated by the team, what will be allowing the business to have governance over what is being pushed to production, and to monitor any preferred or unwanted behaviour of a model.

### Diagram Figure
![Architecture 1](https://dissertationfco.blob.core.windows.net/dissfco/2ndArchitecture.png?)

### Table of the technologies displayed in the architecture diagram

| Technology | Use case |
| --- | --- |
| Kubernetes | Platform used to deploy and orchestrate ML Models, Istio, and Seldon Core. |
| Kubectl | Is a command-line interface installed locally in the cluster administrator’s computer to manage Kubernetes and define Deployment Manifests. |
| Cloud Storage | We will be using a Cloud Storage as a repository for Model Binaries (e.g., TensorFlow, Scikit Learn, Pytorch), so Seldon Core can access them when deploying the service. |
| Seldon Core | Is the deployment solution for ML Models, that also is deployed inside Kubernetes. |
| Istio | Is the service mesh that is in charge of connecting services with other services or ingress/egress endpoints. |
| Istioctl | Is a command-line interface to manage the Istio installation inside a Kubernetes platform. |
| Helm | Helm is a package manager to automate and facilitate deployments in Kubernetes. |
| Lens (optional) | User interface used to monitor and debug deployments/pods in Kubernetes. |
| mlFlow Tracking Server |	This tool automatically will be registering all models that are connected to the mlFlow API. It stores in a database Parameters, Metrics and Metadata. |
| mlFlow Model Registry	| This tool allows teams to register a model in the platform and manages the stage in which the model currently is (e.g., Experimental, Staging, A/B Testing, and Production). |
|PostgreSQL	| Is the databases that mlFlow will be using to store information about the model, and the metadata of the model life cycle. |


### References
1. John, M.M., Olsson, H.H. and Bosch, J. (2021). Towards MLOps: a Framework and Maturity Model. [online] IEEE Xplore. doi:10.1109/SEAA53835.2021.00050.
2. Newell, S. and Marabelli, M. (2015). Strategic Opportunities (and Challenges) of Algorithmic DecisionMaking: A Call for Action on the LongTerm Societal Effects of ‘Datification’. SSRN Electronic Journal. doi:10.2139/ssrn.2644093.